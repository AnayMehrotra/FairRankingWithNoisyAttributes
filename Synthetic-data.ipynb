{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import string\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "import cvxpy as cp\n",
    "import gurobipy\n",
    "\n",
    "import copy, signal\n",
    "import csv, datetime\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy.random as random_numpy\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, rcParams\n",
    "from scipy.stats import uniform, truncnorm\n",
    "\n",
    "from birkhoff import birkhoff_von_neumann_decomposition\n",
    "\n",
    "rng = random_numpy.default_rng(1234)\n",
    "CORES = 5 ## Number of parallel threads to run\n",
    "\n",
    "from birkhoff_edited import fast_decomposition\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally, enter absolute path \n",
    "home_folder = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions and ranking utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistical/storing functions\n",
    "exec(open('helper_funcs.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('utils.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Dimensions of inputs\n",
    "    # W: m x n\n",
    "    # P: m x g\n",
    "    # U: g x n\n",
    "    # L: g x n\n",
    "    # x: m x n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('algorithms.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "source": [
    "# Code to Run Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is adapted from the [Noisy-Fair-Subset-Selection](https://github.com/AnayMehrotra/Noisy-Fair-Subset-Selection) repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def gen_P_toy(m, rand_gen=None):\n",
    "    rng = get_rng(rand_gen)\n",
    "    \n",
    "    P = [[0,0] for i in range(m)]\n",
    "    \n",
    "    mu1 = 0.6; std1 = 0.001 # 5\n",
    "    cnt1 = 0; rand1 = truncnorm.rvs((0-mu1)/std1, (1-mu1)/std1, loc=mu1, scale=std1, size=m, random_state=rng.integers(10000))\n",
    "    \n",
    "    mu2 = 0.05; std2 = 0.001 # 5\n",
    "    cnt2 = 0; rand2 = truncnorm.rvs((0-mu2)/std2, (1-mu2)/std2, loc=mu2, scale=std2, size=m, random_state=rng.integers(10000))\n",
    "    \n",
    "    rand_mix = rng.uniform(0,1,m)\n",
    "    \n",
    "    \n",
    "    fraction_women = 0.40\n",
    "    \n",
    "    for i in range(m):\n",
    "        if rand_mix[i] < (fraction_women - mu2) / (mu1 - mu2): \n",
    "            P[i] = [rand1[cnt1],0]\n",
    "            cnt1 += 1\n",
    "        else: \n",
    "            P[i] = [rand2[cnt2],0]\n",
    "            cnt2 += 1\n",
    "            \n",
    "        P[i][1] = 1 - P[i][0]\n",
    "        \n",
    "    P = np.array(P)\n",
    "    \n",
    "    return P.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_res(results_mean, results_std, utility_mean, utility_std, ITER = 100,\\\n",
    "             fairness_measure = 'Fairness measure', name_occ_list = '', name_occ_list2 = '',\\\n",
    "             exp = 'Synthetic data', m = 100, n = 50, g = 2, ylims=(0.6,1.0), save = True, useILP=False):\n",
    "    num_of_alg = results_mean.shape[1]\n",
    "    num_of_const_steps = results_mean.shape[0]\n",
    "\n",
    "    algo_names = ['This work', 'SJ', 'CSV [Greedy]', 'MC', 'GAK [Det-Greedy]', 'Uncons']\n",
    "    algo_colors = ['#2FA3EB', '#F2B93F', '#F06B56', '#4DF06D', '#604EE6', '#000000', '#804539', 'purple', 'black']\n",
    "    color = {}\n",
    "\n",
    "    # Plot: const vs fairness measure\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(num_of_alg):\n",
    "        x_axis = np.linspace(2, 1, num_of_const_steps)\n",
    "        \n",
    "        res = results_mean[:, i].T\n",
    "        res_err = results_std[:, i].T / np.sqrt(ITER)\n",
    "        \n",
    "        plt.errorbar(x_axis, res, yerr=res_err, fmt=('--' if i == 2 else '-'),\\\n",
    "                     color=algo_colors[i], label=algo_names[i], linewidth=4, alpha=0.9)\n",
    "        \n",
    "    ax.invert_xaxis()\n",
    "    plt.title(f'{exp}\\n$(m,n,g)=$({m},{n},{g}),ITER={ITER},occ_lists=[{name_occ_list},{name_occ_list2}].', fontsize=15)\n",
    "    #plt.ylim(ylims[0], ylims[1])\n",
    "    plt.ylim(np.min(results_mean) - 0.02, np.max(results_mean) + 0.02)    \n",
    "    ax.set_ylabel(f'(Less fair)\\t\\t\\t{fairness_measure}\\t\\t\\t(More fair)',fontsize=23)\n",
    "    ax.set_xlabel('(Looser constraint)\\tFairness const. ($\\\\alpha$)\\t(Stricter constraint)',fontsize=23)\n",
    "    legend = plt.legend(loc='best', shadow=False, fontsize=20)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    \n",
    "    if save: pdf_savefig()\n",
    "    else: plt.show()\n",
    "        \n",
    "    # Plot: const vs utility measure\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(num_of_alg):\n",
    "        x_axis = np.linspace(2, 1, num_of_const_steps)\n",
    "        \n",
    "        util = utility_mean[:, i].T\n",
    "        util_err = utility_std[:, i].T / np.sqrt(ITER)\n",
    "        \n",
    "        plt.errorbar(x_axis, util, yerr=util_err,\\\n",
    "                     color=algo_colors[i], label=algo_names[i], linewidth=4, alpha=0.7)    \n",
    "    ax.invert_xaxis()\n",
    "    ax.set_ylabel(f'Utility',fontsize=23)\n",
    "    plt.title(f'{exp}\\n$(m,n,g)=$({m},{n},{g}),ITER={ITER},occ_lists=[{name_occ_list},{name_occ_list2}].', fontsize=15)\n",
    "    ax.set_xlabel('(Looser constraint)\\tFairness const. ($\\\\alpha$)\\t(Stricter constraint)',fontsize=23)\n",
    "    plt.ylim(np.min(utility_mean) - 0.02, np.max(utility_mean) + 0.02)    \n",
    "    legend = plt.legend(loc='best', shadow=False, fontsize=20)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    \n",
    "    if save: pdf_savefig()\n",
    "    else: plt.show()\n",
    "        \n",
    "    # Plot: fairness vs utility measure\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(num_of_alg):\n",
    "        res = results_mean[:, i].T\n",
    "        res_err = results_std[:, i].T / np.sqrt(ITER)\n",
    "        \n",
    "        util = utility_mean[:, i].T\n",
    "        util_err = utility_std[:, i].T / np.sqrt(ITER)\n",
    "        \n",
    "        plt.errorbar(res, util, xerr=res_err, yerr=util_err,\\\n",
    "                     color=algo_colors[i], label=algo_names[i], linewidth=4, alpha=0.7)\n",
    "    plt.ylim(np.min(utility_mean) - 0.02, np.max(utility_mean) + 0.02)    \n",
    "    plt.xlim(np.min(results_mean) - 0.02, np.max(results_mean) + 0.02)    \n",
    "    plt.title(f'{exp}\\n$(m,n,g)=$({m},{n},{g}),ITER={ITER},occ_lists=[{name_occ_list},{name_occ_list2}].', fontsize=15)\n",
    "    ax.set_ylabel(f'Utility',fontsize=23)\n",
    "    ax.set_xlabel(f'(Less fair)'+'\\t'*23+f'{fairness_measure}'+'\\t'*23+'(More fair)',fontsize=23)\n",
    "    legend = plt.legend(loc='best', shadow=False, fontsize=20)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "    if save: pdf_savefig()\n",
    "    else: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def run_syn_exp(ITERS=20, num_of_const_steps=5, rND_k=49, dist=None,\\\n",
    "                fairness_measure=compute_weighted_risk_diff, fairness_measure_name='Risk diff.',\\\n",
    "                m=100, n=50, g=2, verbose=False, useILP=False, bias_factor=0.5):\n",
    "    \n",
    "    num_of_alg = 6\n",
    "    \n",
    "    if dist is None: dist = np.ones(g)/g\n",
    "    \n",
    "    results_mean = np.zeros((num_of_const_steps, num_of_alg))\n",
    "    results_std = np.zeros((num_of_const_steps, num_of_alg))\n",
    "    \n",
    "    utility_mean = np.zeros((num_of_const_steps, num_of_alg))\n",
    "    utility_std = np.zeros((num_of_const_steps, num_of_alg))\n",
    "    \n",
    "    for ijk, gamma in enumerate(np.linspace(2, 1, num_of_const_steps)):\n",
    "\n",
    "        # fix fairness constraints\n",
    "        L = np.zeros((g,n))\n",
    "        U = get_const_from_dist([0.5*gamma, 0.5*gamma], m, n, g)\n",
    "        \n",
    "        results_per_const = [[] for i in range(num_of_alg)]\n",
    "        utility_per_const = [[] for i in range(num_of_alg)]\n",
    "        \n",
    "        for exp_run in tqdm(range(ITERS)):        \n",
    "            cnt = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    P = gen_P_toy(m, rand_gen=rng) # Probabilities\n",
    "                    PT = np.round(P) # Infer attributes\n",
    "                    trueP = get_true_P(P, m, n, g) # Get true attributes\n",
    "                    W = get_biased_util(P, m, n, g, bias_factor=bias_factor)\n",
    "\n",
    "                    # Find fair ranking \n",
    "                    if useILP:\n",
    "                        x_our = noisy_rank_ilp(W, P, L, U)\n",
    "                    else:\n",
    "                        x_our = noisy_rank_cvz_rounding(W, P, L, U, verbose = False)\n",
    "\n",
    "                    x_greedy = greedy_fair_ranking(W, PT, L, U)    \n",
    "                    x_LP, birkhoff = noisy_rank_basic_rounding(W, PT, L, U, getBirkhoff=True)\n",
    "                    a, rankings = extractBirkhoff(birkhoff, n) # Compute Birkhoff decomposition\n",
    "\n",
    "                    x_SS = subset_selection_algorithm(W[:, 0], P, L[:, -1], U[:, -1], n)\n",
    "                    Lp = get_lower_const_from_dist_linkedIn_det_greedy([0.5*1, 0.5*1], m, n, g)\n",
    "                    Up = get_upper_const_from_dist_linkedIn_det_greedy([0.5*1, 0.5*1], m, n, g)\n",
    "                    x_det_greedy = linkedIn_det_greedy(W, PT, Lp, Up, n) # this assumes that W is a rank 1 metric\n",
    "                    \n",
    "                    x_uncons = greedy_fair_ranking(W, PT, np.zeros_like(L), np.ones_like(L)*2*n)\n",
    "                    \n",
    "                except:\n",
    "                    cnt += 1\n",
    "                    if cnt > 10: break\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            # Compute fairness measures\n",
    "            if verbose: print('This work:')\n",
    "            rd_our = fairness_measure(x_our, trueP, dist, m, n, g, k=rND_k, verbose=False, P=P)\n",
    "            if verbose: print('Greedy algorithm:')\n",
    "            rd_greedy = fairness_measure(x_greedy, trueP, dist, m, n, g, k=rND_k, verbose=False, P=P)\n",
    "            rd_LP = 0\n",
    "            for i, r in enumerate(rankings):\n",
    "                rd_LP += a[i] * fairness_measure(r, trueP, dist, m, n, g, k=rND_k, verbose=False, P=P)\n",
    "            if verbose: print('Subset selection:')\n",
    "            rd_SS = fairness_measure(x_SS, trueP, dist, m, n, g, k=rND_k, verbose=False, P=P)\n",
    "            rd_det_greedy = fairness_measure(x_det_greedy, trueP, dist, m, n, g, k=rND_k)\n",
    "            \n",
    "            rd_uncons = fairness_measure(x_uncons, trueP, dist, m, n, g, k=rND_k)\n",
    "            \n",
    "                \n",
    "            # Print and store results \n",
    "            if verbose: print('$'*15, rd_our, rd_LP, rd_greedy)\n",
    "            results_per_const[0].append(rd_our)\n",
    "            results_per_const[1].append(rd_LP)\n",
    "            results_per_const[2].append(rd_greedy)\n",
    "            results_per_const[3].append(rd_SS)\n",
    "            results_per_const[4].append(rd_det_greedy)\n",
    "            results_per_const[5].append(rd_uncons)\n",
    "            \n",
    "            utility_per_const[0].append(get_utility(W, x_our))\n",
    "            \n",
    "            u_LP = 0\n",
    "            for i, r in enumerate(rankings):\n",
    "                u_LP += a[i] * get_utility(W, r)\n",
    "            \n",
    "            utility_per_const[1].append(u_LP)        \n",
    "            utility_per_const[2].append(get_utility(W, x_greedy))\n",
    "            utility_per_const[3].append(get_utility(W, x_SS))\n",
    "            utility_per_const[4].append(get_utility(W, x_det_greedy))\n",
    "            utility_per_const[5].append(get_utility(W, x_uncons))\n",
    "        \n",
    "        results_mean[ijk] = np.array([np.mean(results_per_const[i]) for i in range(num_of_alg)])\n",
    "        results_std[ijk]  = np.array([np.std(results_per_const[i]) for i in range(num_of_alg)])\n",
    "        \n",
    "        utility_mean[ijk] = np.array([np.mean(utility_per_const[i]) for i in range(num_of_alg)])\n",
    "        utility_std[ijk] = np.array([np.std(utility_per_const[i]) for i in range(num_of_alg)])\n",
    "    \n",
    "    plot_res(results_mean, results_std, utility_mean, utility_std, ITER = ITERS,\\\n",
    "             fairness_measure = fairness_measure, name_occ_list = 'NA', name_occ_list2 = 'NA',\\\n",
    "             exp = 'Synthetic data', m = m, n = n, g = g, save = True, useILP=useILP)\n",
    "    \n",
    "    return results_mean, results_std, utility_mean, utility_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results with weighted risk difference\n",
    "results_mean, results_std, utility_mean, utility_std = run_syn_exp(ITERS=500,\\\n",
    "                                        num_of_const_steps=9, dist=np.ones(2)/2,\\\n",
    "                                        fairness_measure=compute_weighted_risk_diff,\\\n",
    "                                        rND_k=5, m=500, n=25, g=2, bias_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results with weighted selection lift \n",
    "results_mean, results_std, utility_mean, utility_std = run_syn_exp(ITERS=500,\\\n",
    "                                        num_of_const_steps=9, dist=np.ones(2)/2,\\\n",
    "                                        fairness_measure=compute_weighted_selec_lift,\\\n",
    "                                        rND_k=5, m=500, n=25, g=2, bias_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
