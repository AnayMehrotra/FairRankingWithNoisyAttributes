{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import string\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "import cvxpy as cp\n",
    "import gurobipy\n",
    "\n",
    "import copy, signal\n",
    "import csv, datetime\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy.random as random_numpy\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc, rcParams\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from birkhoff import birkhoff_von_neumann_decomposition\n",
    "\n",
    "rng = random_numpy.default_rng(1234)\n",
    "CORES = 5 ## Number of parallel threads to run\n",
    "\n",
    "from birkhoff_edited import fast_decomposition\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally, enter absolute path \n",
    "home_folder = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = lambda str : f\"print(\\\"{str}\\\",\\\"=\\\",eval(\\\"{str}\\\"))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions and ranking utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('utils.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('helper_funcs.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('algorithms.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation with real-world image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is adapted from the [Noisy-Fair-Subset-Selection](https://github.com/AnayMehrotra/Noisy-Fair-Subset-Selection) repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from numpy import matlib\n",
    "from varname import nameof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = home_folder+'occupations_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     31
    ]
   },
   "outputs": [],
   "source": [
    "def stats_occupations_ds(file, verbose=0):\n",
    "    occupations = {}\n",
    "    with open(file) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if row[0] not in occupations: occupations[row[0]]=[]\n",
    "            occupations[row[0]].append({'image':row[0]+\"/\"+row[1], 'gender':row[2],'skin_tone':row[3]})\n",
    "            line_count += 1\n",
    "    occupations_stats = {}\n",
    "    for o in occupations:\n",
    "        tot_men = 0; tot_women = 0; tot_dark = 0; tot_light = 0;\n",
    "        for img in occupations[o]:\n",
    "            tot_men = tot_men + (img['gender']=='Male')\n",
    "            tot_women = tot_women + (img['gender']=='Female')\n",
    "            tot_dark = tot_dark + (img['skin_tone']=='dark')\n",
    "            tot_light = tot_light + (img['skin_tone']=='light')\n",
    "        occupations_stats[o] = {\"total\": len(occupations[o]), \"tot_men\": tot_men,\\\n",
    "                                \"tot_women\": tot_women, \"tot_dark\": tot_dark,\\\n",
    "                                \"tot_light\": tot_light}\n",
    "\n",
    "    # prints file in csv format.\n",
    "    if verbose:\n",
    "        for o in occupations_stats: print(o,\",\",occupations_stats[o][\"tot_men\"],\",\",\\\n",
    "                                        occupations_stats[o][\"tot_women\"],\",\",\\\n",
    "                                        occupations_stats[o][\"tot_dark\"],\",\",\\\n",
    "                                        occupations_stats[o][\"tot_light\"])\n",
    "    return occupations, occupations_stats\n",
    "\n",
    "occupations, occupations_stats = stats_occupations_ds(data_file)\n",
    "\n",
    "def filter_occupations(tau_rule=0.8, least_number_of_humans=50, verbose=0):\n",
    "    _, stats = stats_occupations_ds(data_file);\n",
    "    women_typical = []; men_typical = []; neutral = []\n",
    "    for o in stats:\n",
    "        if stats[o][\"tot_men\"]+stats[o][\"tot_women\"] >= least_number_of_humans:\n",
    "            tot=stats[o][\"tot_men\"]+stats[o][\"tot_women\"]\n",
    "            if stats[o][\"tot_women\"]/tot >= tau_rule: women_typical.append(o)\n",
    "            elif stats[o][\"tot_men\"]/tot >= tau_rule: men_typical.append(o)\n",
    "            else: neutral.append(o)\n",
    "    if verbose:\n",
    "        print(\"women_typical:\")\n",
    "        for o in women_typical: print(o, end=\",\")\n",
    "        print(\"men_typical:\")\n",
    "        for o in men_typical: print(o, end=\",\")\n",
    "        print(\"neutral:\")\n",
    "        for o in neutral: print(o, end=\",\")\n",
    "    return women_typical, men_typical, neutral\n",
    "\n",
    "all_occ, _, _ = filter_occupations(0,0,0)\n",
    "all_occ.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predictions using the classfier might be computationially heavy.\n",
    "# The user can avoid recomputing the predictions, by using our precomputed results on the Occupations dataset.\n",
    "# To use the pre-computed results set `runClassifier = False`\n",
    "# Otherwise set `runClassifier = True` \n",
    "\n",
    "# Remarks:\n",
    "# To run the classifier you need a suitable caffe installation.\n",
    "# We refer the user to https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/ for a tutorial on the face detector we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runClassifier = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.A Preprocessing occupations dataset to generate cropped images (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_folder=\"\"\n",
    "\n",
    "if runClassifier: \n",
    "    home_folder+\"Occupations_dataset_images/\"\n",
    "\n",
    "crop_folder=home_folder+\"image-subset-selection/Occupations-dataset/Occupations-Datatset-2019/Occupations_dataset_images_cropped/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.A.1 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def detect_faces(img, net, thresh=0.5,verbose=0):\n",
    "    # source: https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/#download-the-code\n",
    "    # load the input image and construct an input blob for the image\n",
    "    # by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "    image = cv2.imread(img)\n",
    "    try: (h, w) = image.shape[:2]\n",
    "    except:\n",
    "        print(\"skipped!\")\n",
    "        return -1\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    # pass the blob through the network and obtain the detections andpredictions\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    faces=[]\n",
    "    # loop over the detections\n",
    "    for i in range(detections.shape[1]):\n",
    "        # extract the confidence (i.e., probability) associated with the prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > thresh:\n",
    "            # compute the (x, y)-coordinates of the bounding box for the object\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            faces.append([startX, startY, endX, endY])\n",
    "            #\n",
    "            if verbose:\n",
    "                ##draw the bounding box of the face along with the associated  probability\n",
    "                text = \"{:.2f}%\".format(confidence * 100);\n",
    "                y = startY - 10 if startY - 10 > 10 else startY + 10;\n",
    "                cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2);\n",
    "                cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "    # show the output image\n",
    "    if verbose: cv2.imshow(\"Output\", image); cv2.waitKey(0); cv2.destroyWindow(\"Output\")\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_faces(image, faces, verbose=0):\n",
    "    # set default margin\n",
    "    pad=0.4 ## cropping margin\n",
    "    # size of face\n",
    "    # extractSubImage(img,box,pad)\n",
    "    cropped_faces=[]\n",
    "    for box in faces:\n",
    "        sz =[box[3]-box[1]+1, box[2]-box[0]+1]\n",
    "        #add margin\n",
    "        new_crop = [0]*4\n",
    "        new_crop[0]=round(box[0]-pad*sz[1]);\n",
    "        new_crop[1]=round(box[1]-pad*sz[0]);\n",
    "        new_crop[2]=round(box[2]+pad*sz[1]);\n",
    "        new_crop[3]=round(box[3]+pad*sz[0]);\n",
    "        # size of face with margin\n",
    "        new_sz=[new_crop[3]-new_crop[1]+1, new_crop[2]-new_crop[0]+1]\n",
    "        # ensure that the region cropped from the original image with margin doesn't go beyond the image size\n",
    "        crop = [0]*4\n",
    "        crop[0]=max(new_crop[0],0);\n",
    "        crop[1]=max(new_crop[1],0);\n",
    "        crop[2]=min(new_crop[2],image.shape[1]-1);\n",
    "        crop[3]=min(new_crop[3],image.shape[0]-1);\n",
    "        # size of the actual region being cropped from the original image\n",
    "        crop_sz=[crop[3]-crop[1]+1, crop[2]-crop[0]+1]\n",
    "        # create new image\n",
    "        new_img=np.zeros((new_sz[0],new_sz[1],image.shape[2]), np.uint8)\n",
    "        # coordinates of region taken out of the original image in the new image\n",
    "        new_loc=[0]*4\n",
    "        new_loc[0]=crop[0]-new_crop[0];\n",
    "        new_loc[1]=crop[1]-new_crop[1];\n",
    "        new_loc[2]=new_loc[0]+crop_sz[1]-1;\n",
    "        new_loc[3]=new_loc[1]+crop_sz[0]-1;\n",
    "        # coordinates of the face in the new image\n",
    "        # obj_location=[0]*4\n",
    "        # for i in range(4): obj_location[i]=new_loc[i]+box[i]-crop[i]+1;\n",
    "        # do the crop\n",
    "        try: new_img[new_loc[1]:new_loc[3]+1, new_loc[0]:new_loc[2]+1, :] = image[crop[1]:crop[3]+1,crop[0]:crop[2]+1,:];\n",
    "        except:\n",
    "            print(\"skipped!\");\n",
    "            debug(\"new_img.shape, image.shape\");\n",
    "            return -1;\n",
    "        # if margin goes beyond the size of the image, repeat last row of pixels\n",
    "        for c in range(image.shape[2]):\n",
    "            if new_loc[1]>0:\n",
    "                new_img[:new_loc[1],:,c]  = np.matlib.repmat(new_img[new_loc[1],:,c],new_loc[1],1);\n",
    "            if new_loc[3]<new_img.shape[0]-1:\n",
    "                new_img[new_loc[3]+1:,:,c]=np.matlib.repmat(new_img[new_loc[3],:,c],new_img.shape[0]-new_loc[3]-1,1);\n",
    "            if new_loc[0]>0:\n",
    "                new_img[:,:new_loc[0],c]  =np.matlib.repmat(new_img[:,new_loc[0],c],new_loc[0],1).T;\n",
    "            if new_loc[2]<new_img.shape[1]-1:\n",
    "                new_img[:,new_loc[2]+1:,c]=np.matlib.repmat(new_img[:,new_loc[2],c],new_img.shape[1]-new_loc[2]-1,1).T;\n",
    "        cropped_faces.append(new_img)\n",
    "        if verbose: cv2.imshow(\"padded_image\", new_img); cv2.waitKey(0); cv2.destroyWindow(\"padded_image\")\n",
    "    return cropped_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.A.2 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if runClassifier:\n",
    "    prototxt=home_folder+\"deploy.prototxt.txt\"\n",
    "    model=home_folder+\"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "    net = cv2.dnn.readNetFromCaffe(prototxt, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.A.3 Code to crop and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if runClassifier:\n",
    "    def solve(folder, occupation, num,net):\n",
    "        file = occupation+\"/0000\"+(\"0\" if num<10 else \"\")+str(num)\n",
    "        if num == 100: file = occupation+\"/000100\"\n",
    "        print(occupation, num)\n",
    "        tmp = folder+file+\".jpg\"\n",
    "        image = cv2.imread(tmp)\n",
    "        face_boxes = detect_faces(tmp,net)\n",
    "        if face_boxes == -1: return\n",
    "        cropped_faces=extract_faces(image, face_boxes)\n",
    "        if cropped_faces == -1: return\n",
    "        i=0\n",
    "        for f in cropped_faces: cv2.imwrite(crop_folder+file+\"_\"+str(i)+\".jpg\",f); i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.A.4 Run classifier and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runClassifier:\n",
    "    occ = list(occupations_stats.keys()); occ.sort()\n",
    "    for o in occ:\n",
    "        for i in range(1,101): solve(occ_folder, o, i, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runClassifier: del(net) # delete net to save RAM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.B Helper functions (2; pre-processing and generating predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def predict_in_parallel(imgs, llim=0, rlim=0):\n",
    "    # Set the right path to your model definition file, pretrained model weights,\n",
    "    # and the image you would like to classify.\n",
    "    MODEL_FILE = home_folder + '../rothe2016deep/gender-prediction/models/gender.prototxt'\n",
    "    PRETRAINED = home_folder + '../rothe2016deep/gender-prediction/models/gender.caffemodel'\n",
    "    \n",
    "    \n",
    "    caffe.set_mode_cpu() # load the model\n",
    "    # caffe.set_device(0)\n",
    "    \n",
    "    net = caffe.Classifier(MODEL_FILE, PRETRAINED, channel_swap=(2,1,0), raw_scale=255, image_dims=(256, 256))\n",
    "    print(\"successfully loaded classifier\")\n",
    "    \n",
    "    # Not storing the images (keeps the memory requirement down)\n",
    "    pred = []\n",
    "    i = 0\n",
    "    for x in tqdm(imgs[llim:rlim]):\n",
    "        i += 1\n",
    "        IMAGE_FILE = crop_folder + x['image'].split('.')[0] + \"_0\" + \".jpg\"\n",
    "        \n",
    "        try:\n",
    "            img = caffe.io.load_image(IMAGE_FILE)\n",
    "            pred.extend(net.predict([img]))\n",
    "        except Exception as exc:\n",
    "            print(f\"found bad image: {x['image']}!\")\n",
    "            pred.append([0,0])\n",
    "    pred=np.array(pred)\n",
    "    #\n",
    "    debug(\"len(pred)\")\n",
    "    # pred[i] = (percent_woman, percent_man)\n",
    "    #\n",
    "    file = open('pred_for_tau00_min00_'+str(llim)+\"_\"+str(rlim), 'wb')\n",
    "    pickle.dump(pred, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8,
     15,
     19,
     99,
     145
    ]
   },
   "outputs": [],
   "source": [
    "def get_images_with_humans(o_list=[]):\n",
    "    imgs=[]\n",
    "    occupations, _ = stats_occupations_ds(data_file);\n",
    "    for o in o_list:\n",
    "        for im in occupations[o]:\n",
    "            if im['gender']!='NA': imgs.append(im)\n",
    "    return imgs\n",
    "\n",
    "def get_images_all(o_list=[]):\n",
    "    imgs=[]\n",
    "    occupations, _ = stats_occupations_ds(data_file);\n",
    "    for o in o_list:\n",
    "        for im in occupations[o]: imgs.append(im)\n",
    "    return imgs\n",
    "\n",
    "def ok_pred(pred):\n",
    "    if pred[0]+pred[1]>0.5: return True\n",
    "    return False\n",
    "\n",
    "def generate_bins(imgs, num_bins=20, predict_now=runClassifier, verbose=0):\n",
    "    if predict_now: \n",
    "        # predicitions take time; run only once.\n",
    "        \n",
    "        predict_in_parallel(imgs, 0, 500)\n",
    "        predict_in_parallel(imgs, 500, 2500)\n",
    "        predict_in_parallel(imgs, 2500, 4500)\n",
    "        predict_in_parallel(imgs, 4500, 6000)\n",
    "        \n",
    "        pred=[]\n",
    "        file = open('pred_for_tau00_min00_0_500', 'rb')\n",
    "        pred.extend(list(pickle.load(file, encoding='latin1')))\n",
    "        file = open('pred_for_tau00_min00_500_2500', 'rb')\n",
    "        pred.extend(list(pickle.load(file, encoding='latin1')))\n",
    "        file = open('pred_for_tau00_min00_2500_4500', 'rb')\n",
    "        pred.extend(list(pickle.load(file, encoding='latin1')))\n",
    "        file = open('pred_for_tau00_min00_4500_6000', 'rb')\n",
    "        pred.extend(list(pickle.load(file, encoding='latin1')))\n",
    "        debug(\"len(pred)\")\n",
    "        # Note: pred[i] = (percent_woman, percent_man)\n",
    "        \n",
    "        file = open(home_folder+'pre-predicted-labels/pred_for_tau0_6_min00', 'wb')\n",
    "        pickle.dump(pred, file)\n",
    "    else: \n",
    "        ## Use values calculated earlier to save computation\n",
    "        pred=[]\n",
    "        file = open(home_folder+'pre-predicted-labels/pred_for_tau0_6_min00', 'rb')\n",
    "        pred.extend(list(pickle.load(file, encoding='latin1')))\n",
    "        pred=np.array(pred)\n",
    "    \n",
    "    cnt=0;bad_ind=[]\n",
    "    for i in range(len(pred)):\n",
    "        if not ok_pred(pred[i]): cnt+=1; bad_ind.append(i)\n",
    "    if verbose: print(\"Percentage of images without bounding boxes: \", cnt/len(imgs)*100)\n",
    "    \n",
    "    for i in range(len(imgs)): imgs[i]['pred'] = pred[i]\n",
    "    \n",
    "    # Generating bins\n",
    "    tmp = []\n",
    "    bins = np.linspace(0, 1, num_bins)\n",
    "    for it in pred:\n",
    "        if ok_pred(it): tmp.append(it[0])\n",
    "    digi = np.digitize(tmp, bins)\n",
    "    cnt_bin={}; cnt_bin_f={}; #number of females in bin\n",
    "    cnt=0; cntf=0 # cnt of females which have a prediction\n",
    "    for i in range(1,num_bins): cnt_bin_f[i]=0; cnt_bin[i]=0;\n",
    "    for i in digi: cnt_bin[i]+=1\n",
    "    for i in range(len(imgs)):\n",
    "        if not ok_pred(pred[i]): continue\n",
    "        if imgs[i]['gender']=='Female': cntf+=1; cnt_bin_f[digi[cnt]]+=1\n",
    "        cnt+=1\n",
    "    assert(cnt==len(tmp))\n",
    "    frac_f=[cnt_bin_f[i]/(cnt_bin[i]+1e-5) for i in range(1,num_bins)]\n",
    "    frac_f=np.array(frac_f)\n",
    "    arr_cnt_bin = [cnt_bin[i] for i in range(1,num_bins)]; arr_cnt_bin=np.array(arr_cnt_bin)\n",
    "    \n",
    "    # Print\n",
    "    if verbose:\n",
    "        print(f\"Number of images with predictions: {len(tmp)}\")\n",
    "        print(f\"Number of images marked women with predictions: {cntf}\")\n",
    "        print(f\"Number of bins: {num_bins}\")\n",
    "        print(f\"Fraction of females in bins: \")\n",
    "        debug(\"np.round(frac_f, 2)\")\n",
    "        print(f\"Number of images in bins: \")\n",
    "        debug(\"arr_cnt_bin\")\n",
    "    \n",
    "    #\n",
    "    acc=0 # number of correct predictions for women\n",
    "    for i in range(len(imgs)):\n",
    "        if not ok_pred(pred[i]): continue\n",
    "        if imgs[i]['gender']=='Female' and pred[i][0]>=0.5: acc+=1\n",
    "    if verbose: print(f\"Accuracy on women={round(acc/cntf*100, 2)}%\")\n",
    "    acc=0 # number of correct predictions for men\n",
    "    for i in range(len(imgs)):\n",
    "        if not ok_pred(pred[i]): continue\n",
    "        if imgs[i]['gender']=='Male' and pred[i][0]<0.5: acc+=1\n",
    "    if verbose: print(f\"Accuracy on men={round(acc/(len(tmp)-cntf)*100,2)}%\")\n",
    "    #\n",
    "    return pred, bins, frac_f\n",
    "\n",
    "def get_prediction_stats(imgs,num_bins=20,verbose=1):\n",
    "    # Expects images from `get_prediction_and_image` (this pre-processes them)\n",
    "    bins = np.linspace(0, 1, num_bins)\n",
    "    tmp = []\n",
    "    for i in range(len(imgs)):\n",
    "        if ok_pred(imgs[i]['pred']): tmp.append(imgs[i]['pred'][0])\n",
    "    assert(len(tmp)==len(imgs)) # Expects images from `get_prediction_and_image` (this pre-processes them)\n",
    "    digi = np.digitize(tmp, bins)\n",
    "    cnt_bin={}; cnt_bin_f={}; #number of females in bin\n",
    "    cnt=0; cntf=0 # cnt of females which have a prediction\n",
    "    for i in range(1,num_bins): cnt_bin_f[i]=0; cnt_bin[i]=0;\n",
    "    for i in digi: cnt_bin[i]+=1\n",
    "    for i in range(len(imgs)):\n",
    "        if not ok_pred(imgs[i]['pred']): \n",
    "            print(\"Image prediction not okay\")\n",
    "            continue\n",
    "        if imgs[i]['gender']=='Female': cntf+=1; cnt_bin_f[digi[cnt]]+=1\n",
    "        cnt+=1\n",
    "    if verbose: print(cnt, len(tmp))\n",
    "    assert(cnt==len(tmp))\n",
    "    frac_f=[cnt_bin_f[i]/(cnt_bin[i]+1e-5) for i in range(1,num_bins)]\n",
    "    frac_f=np.array(frac_f)\n",
    "    arr_cnt_bin = [cnt_bin[i] for i in range(1,num_bins)]; arr_cnt_bin=np.array(arr_cnt_bin)\n",
    "    # Print\n",
    "    if verbose:\n",
    "        print(f\"Number of images with predictions: {len(tmp)}\")\n",
    "        print(f\"Number of images marked women with predictions: {cntf}\")\n",
    "        print(f\"Number of bins: {num_bins}\")\n",
    "        print(f\"Fraction of females in bins: \")\n",
    "        debug(\"np.round(frac_f, 2)\")\n",
    "        print(f\"Number of images in bins: \")\n",
    "        debug(\"arr_cnt_bin\")\n",
    "    #\n",
    "    acc=0 # number of correct predictions for women\n",
    "    for it in imgs:\n",
    "        if not ok_pred(it['pred']): continue\n",
    "        if it['gender']=='Female' and it['pred'][0]>=0.5: acc+=1\n",
    "    if verbose: print(f\"Accuracy on women={round(acc/cntf*100, 2)}%\")\n",
    "    acc=0 # number of correct predictions for men\n",
    "    for it in imgs:\n",
    "        if not ok_pred(it['pred']): continue\n",
    "        if it['gender']=='Male' and it['pred'][0]<0.5: acc+=1\n",
    "    if verbose: print(f\"Accuracy on men={round(acc/(len(tmp)-cntf)*100,2)}%\")\n",
    "    #\n",
    "    return pred, bins, frac_f\n",
    "\n",
    "def calibrate_pred(pred, c_bins=[], c_frac_f=[]):\n",
    "    if len(c_frac_f)!=0 and len(c_bins)!=0: \n",
    "        return [c_frac_f[np.digitize(pred[0], c_bins)-1], 1-c_frac_f[np.digitize(pred[0], c_bins)-1]]\n",
    "    return [frac_f[np.digitize(pred[0], bins)-1], 1-frac_f[np.digitize(pred[0], bins)-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.B.1 Generating all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = get_images_with_humans(all_occ) ## All images with humans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.B.2 Load predictions and bin them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, bins, frac_f = generate_bins(imgs, num_bins=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.C Helper functions (3; sample candidates and utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     15,
     36
    ]
   },
   "outputs": [],
   "source": [
    "def get_prediction_and_image(o_list=[],custom_cal=0):\n",
    "    imgs = get_images_with_humans(all_occ)\n",
    "    pred, bins, frac_f = generate_bins(imgs)\n",
    "    ## Remove bad images from images and add pred valueus to images\n",
    "    imgs_new = []\n",
    "    for i in range(len(imgs)):\n",
    "        if ok_pred(pred[i]) and imgs[i]['image'].split('/')[0] in o_list:\n",
    "            imgs[i]['pred']=pred[i]; imgs_new.append(imgs[i]);\n",
    "    imgs_new = np.array(imgs_new)\n",
    "    #\n",
    "    c_bins=[]; c_frac_f=[]\n",
    "    if custom_cal:\n",
    "        _, c_bins, c_frac_f = get_prediction_stats(imgs=imgs_new,verbose=0)\n",
    "    return imgs_new, c_bins, c_frac_f\n",
    "\n",
    "def gen_candidates_image(m,imgs=[],c_bins=[], c_frac_f=[]):\n",
    "    \n",
    "    ## shuffle images (in imgs) and pick m of thems\n",
    "    if m > len(imgs): raise Exception(\"m larger than the number of images!\")\n",
    "    \n",
    "    ## construct q from the bins calculated earlier.\n",
    "    subset = random.sample(list(imgs),m)\n",
    "    \n",
    "    P = np.array([calibrate_pred(s['pred'], c_bins=c_bins, c_frac_f=c_frac_f) for s in subset])\n",
    "    P = P.T\n",
    "    \n",
    "    trueP = np.zeros_like(P) \n",
    "    \n",
    "    for i in range(m):\n",
    "        trueP[0, i] = (subset[i]['gender'] == 'Female')\n",
    "        trueP[1, i] = 1 - trueP[0, i]\n",
    "    \n",
    "    \n",
    "    return np.array(subset), trueP, P\n",
    "\n",
    "utility_type_dict={0:'DCG (100/log(r+1))', 1:'Unif[0,1]', 2:'100/(r+1)', 3:'100-r'}\n",
    "def gen_utility_image(subset, utility_type=0, multiplier=1, n=100, m=100):\n",
    "    ## read image position and result utility\n",
    "    # Utility types: 0==DCG, 1==Uniform, 2==Power-law (exp=1)\n",
    "    w = []\n",
    "    for img in subset:\n",
    "        r = int(img['image'].split('/')[1].split('.')[0]) ## rank\n",
    "        assert(multiplier==1)\n",
    "        if utility_type==0: w.append(100/np.log(r+1)+rng.uniform(0,1)) # 100/np.log(r+1) is at least 20\n",
    "        elif utility_type==1: w.append(rng.uniform(0,1))\n",
    "        elif utility_type==2: w.append(100/(r+1)+0.1*rng.uniform(0,1)) # 100/(r+1) is at least 1\n",
    "        elif utility_type==3: w.append(100-r+rng.uniform(0,1)) # 100/(r+1) is at least 1\n",
    "    \n",
    "    w = np.array(w).reshape((m,1))\n",
    "    v = [1/np.log(j+1+1) for j in range(n)]\n",
    "    W = w * v\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compute Qgrp\n",
    "p = 2\n",
    "m = 4494\n",
    "n = 100\n",
    "Qgrp_image = np.zeros((2,2))\n",
    "\n",
    "# Sample\n",
    "imgs, c_bins, c_frac_f = get_prediction_and_image(all_occ,custom_cal=0)\n",
    "cnd, trueP, P = gen_candidates_image(m, imgs, c_bins = c_bins, c_frac_f = c_frac_f)\n",
    "W = gen_utility_image(cnd, utility_type=0, multiplier=1, n=n, m=m)\n",
    "\n",
    "\n",
    "print(\"Fraction Female: \", np.mean(trueP[0, :]))\n",
    "print(\"Fraction Male: \", np.mean(trueP[1, :]))\n",
    "print('')\n",
    "\n",
    "tmp = ['Female', 'Male']\n",
    "for (i,gi), (j,gj) in itertools.product(enumerate(tmp), enumerate(tmp)):\n",
    "    tot = np.sum( [i == np.argmax(P[:, t]) for t in range(m)])\n",
    "    typ_t = np.sum( [(gj == cnd[t]['gender'])*(i == np.argmax(P[:, t])) for t in range(m)])\n",
    "    Qgrp_image[i][j] = typ_t/tot\n",
    "eval(debug('Qgrp_image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, c_bins, c_frac_f = get_prediction_and_image(all_occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.D Main code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_res(results_mean, results_std, utility_mean, utility_std, ITER = 100,\\\n",
    "             fairness_measure = 'Fairness measure', name_occ_list = '', name_occ_list2 = '',\\\n",
    "             exp = 'Synthetic data', m = 100, n = 50, g = 2, ylims=(0.6,1.0), save = True, useILP=False):\n",
    "    num_of_alg = results_mean.shape[1]\n",
    "    num_of_const_steps = results_mean.shape[0]\n",
    "\n",
    "    algo_names = ['This work', 'SJ', 'CSV [Greedy]', 'MC', 'GAK [Det-Greedy]', 'Uncons']\n",
    "    algo_colors = ['#2FA3EB', '#F2B93F', '#F06B56', '#4DF06D', '#604EE6', '#000000', '#804539', 'purple', 'black']\n",
    "    color = {}\n",
    "\n",
    "    # Plot: const vs fairness measure\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(num_of_alg):\n",
    "        x_axis = np.linspace(2, 1, num_of_const_steps)\n",
    "        \n",
    "        res = results_mean[:, i].T\n",
    "        res_err = results_std[:, i].T / np.sqrt(ITER)\n",
    "        \n",
    "        plt.errorbar(x_axis, res, yerr=res_err, fmt=('--' if i == 2 else '-'),\\\n",
    "                     color=algo_colors[i], label=algo_names[i], linewidth=4, alpha=0.9)\n",
    "        \n",
    "    ax.invert_xaxis()\n",
    "    plt.title(f'{exp}\\n$(m,n,g)=$({m},{n},{g}),ITER={ITER},occ_lists=[{name_occ_list},{name_occ_list2}].', fontsize=15)\n",
    "    # plt.ylim(ylims[0], ylims[1])\n",
    "    plt.ylim(np.min(results_mean) - 0.02, np.max(results_mean) + 0.02)    \n",
    "    ax.set_ylabel(f'(Less fair)\\t\\t\\t{fairness_measure}\\t\\t\\t(More fair)',fontsize=23)\n",
    "    ax.set_xlabel('(Looser constraint)\\tFairness const. ($\\\\alpha$)\\t(Stricter constraint)',fontsize=23)\n",
    "    legend = plt.legend(loc='best', shadow=False, fontsize=20)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    \n",
    "    if save: pdf_savefig()\n",
    "    else: plt.show()\n",
    "    \n",
    "    # 2 corresponds to the greedy algorithm\n",
    "    max_utility = np.max(utility_mean[:, 2])\n",
    "        \n",
    "    # Plot: const vs utility measure\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(num_of_alg):\n",
    "        x_axis = np.linspace(2, 1, num_of_const_steps)\n",
    "        \n",
    "        util = utility_mean[:, i].T / max_utility\n",
    "        util_err = utility_std[:, i].T / np.sqrt(ITER) / max_utility\n",
    "        \n",
    "        plt.errorbar(x_axis, util, yerr=util_err,\\\n",
    "                     color=algo_colors[i], label=algo_names[i], linewidth=4, alpha=0.7)    \n",
    "    \n",
    "    ax.invert_xaxis()\n",
    "    ax.set_ylabel(f'Utility',fontsize=23)\n",
    "    plt.title(f'{exp}\\n$(m,n,g)=$({m},{n},{g}),ITER={ITER},occ_lists=[{name_occ_list},{name_occ_list2}].', fontsize=15)\n",
    "    ax.set_xlabel('(Looser constraint)\\tFairness const. ($\\\\alpha$)\\t(Stricter constraint)',fontsize=23)\n",
    "    # plt.ylim(0.85, np.max(utility_mean / max_utility) * 1.01)\n",
    "    plt.ylim(np.min(utility_mean) - 0.02, np.max(utility_mean) + 0.02)\n",
    "    legend = plt.legend(loc='best', shadow=False, fontsize=20)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    \n",
    "    if save: pdf_savefig()\n",
    "    else: plt.show()\n",
    "        \n",
    "    # Plot: fairness vs utility measure\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(num_of_alg):\n",
    "        res = results_mean[:, i].T\n",
    "        res_err = results_std[:, i].T / np.sqrt(ITER)\n",
    "        \n",
    "        util = utility_mean[:, i].T / max_utility\n",
    "        util_err = utility_std[:, i].T / np.sqrt(ITER) / max_utility\n",
    "        \n",
    "        plt.errorbar(res, util, xerr=res_err, yerr=util_err,\\\n",
    "                     color=algo_colors[i], label=algo_names[i], linewidth=4, alpha=0.7)\n",
    "    # plt.ylim(0.85, np.max(utility_mean / max_utility) * 1.01)\n",
    "    plt.ylim(np.min(utility_mean) / max_utility - 0.02, np.max(utility_mean) / max_utility + 0.02)    \n",
    "    plt.xlim(np.min(results_mean) - 0.02, np.max(results_mean) + 0.02)    \n",
    "    plt.title(f'{exp}\\n$(m,n,g)=$({m},{n},{g}),ITER={ITER},occ_lists=[{name_occ_list},{name_occ_list2}].', fontsize=15)\n",
    "    ax.set_ylabel(f'Utility',fontsize=23)\n",
    "    ax.set_xlabel(f'(Less fair)'+'\\t'*23+f'{fairness_measure}'+'\\t'*23+'(More fair)',fontsize=23)\n",
    "    legend = plt.legend(loc='best', shadow=False, fontsize=20)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "    if save: pdf_savefig()\n",
    "    else: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def run_syn_exp_image(ITERS=20, num_of_const_steps=5, rND_k=n-1, dist=None,\\\n",
    "                fairness_measure=compute_weighted_risk_diff,\\\n",
    "                fairness_measure_name='Risk diff.', m=100, n=50, g=2,\\\n",
    "                occ_list=[], occ_list2=[], name_occ_list = 'NA', name_occ_list2 = 'NA',\\\n",
    "                verbose=False, useILP=False):\n",
    "    \n",
    "    num_of_alg = 6\n",
    "    \n",
    "    imgs, _, _ = get_prediction_and_image(occ_list)\n",
    "    imgs2, _, _ = get_prediction_and_image(occ_list2)\n",
    "    \n",
    "    if dist is None: dist = np.ones(g) / g\n",
    "    \n",
    "    results_mean = np.zeros((num_of_const_steps, num_of_alg))\n",
    "    results_std = np.zeros((num_of_const_steps, num_of_alg))\n",
    "    \n",
    "    utility_mean = np.zeros((num_of_const_steps, num_of_alg))\n",
    "    utility_std = np.zeros((num_of_const_steps, num_of_alg))\n",
    "\n",
    "    for ijk, gamma in enumerate(np.linspace(2, 1, num_of_const_steps)):\n",
    "        \n",
    "        # fix fairness constraints\n",
    "        L = np.zeros((g,n))\n",
    "        U = get_const_from_dist([0.5*gamma, 0.5*gamma], m, n, g)\n",
    "        \n",
    "        results_per_const = [[] for i in range(num_of_alg)]\n",
    "        utility_per_const = [[] for i in range(num_of_alg)]\n",
    "        \n",
    "        for exp_run in tqdm(range(ITERS)):        \n",
    "            cnt = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    # Generate data \n",
    "                    ma = int(len(imgs)*1.0/(len(imgs)+len(imgs2)) * m)\n",
    "                    mb = m-ma\n",
    "\n",
    "                    cnda, truePa, Pa = gen_candidates_image(ma, imgs, c_bins=c_bins, c_frac_f=c_frac_f)\n",
    "                    cndb, truePb, Pb = gen_candidates_image(mb, imgs2, c_bins=c_bins, c_frac_f=c_frac_f)\n",
    "\n",
    "                    for j in range(mb):\n",
    "                        if cndb[j]['gender'] == 'Female':\n",
    "                            cndb[j]['gender'] = 'Male'\n",
    "                        else:\n",
    "                            cndb[j]['gender'] = 'Female'\n",
    "                    cnd = np.array(list(cnda)+list(cndb))\n",
    "\n",
    "                    trueP = np.concatenate([truePa.T, (1-truePb).T]).T\n",
    "                    P = np.concatenate([Pa.T, (1-Pb).T]).T\n",
    "                    PT = np.round(P) # P thresholded\n",
    "                    W = gen_utility_image(cnd, utility_type=2, multiplier=1, n=n, m=m)\n",
    "\n",
    "                    # Find fair ranking \n",
    "\n",
    "                    if useILP:\n",
    "                        x_our = noisy_rank_ilp(W, P, L, U)\n",
    "                    else:\n",
    "                        x_our = noisy_rank_cvz_rounding(W, P, L, U, verbose = False)\n",
    "\n",
    "                    x_greedy = greedy_fair_ranking(W, PT, L, U)\n",
    "\n",
    "                    x_LP, birkhoff = noisy_rank_basic_rounding(W, PT, L, U, getBirkhoff=True)\n",
    "                    a, rankings = extractBirkhoff(birkhoff, n) # Compute Birkhoff decomposition\n",
    "                    if verbose: print(f'Number of rankings = {len(rankings)}')\n",
    "\n",
    "                    x_SS = subset_selection_algorithm(W[:, 0], P, L[:, -1], U[:, -1], n)\n",
    "                    Lp = get_lower_const_from_dist_linkedIn_det_greedy([0.5*1, 0.5*1], m, n, g)\n",
    "                    Up = get_upper_const_from_dist_linkedIn_det_greedy([0.5*1, 0.5*1], m, n, g)\n",
    "                    x_det_greedy = linkedIn_det_greedy(W, PT, Lp, Up, n) # this assumes that W is a rank 1 metric\n",
    "                    \n",
    "                    x_uncons = greedy_fair_ranking(W, PT, np.zeros_like(L), np.ones_like(L)*2*n)\n",
    "                    \n",
    "                except:\n",
    "                    cnt += 1\n",
    "                    if cnt > 10: break\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # Compute fairness measures\n",
    "            # print('This work:')\n",
    "            rd_our = fairness_measure(x_our, trueP, dist, m, n, g, k=rND_k, verbose=False, P=P)\n",
    "            # print('Greedy algorithm:')\n",
    "            rd_greedy = fairness_measure(x_greedy, trueP, dist, m, n, g, k=rND_k, verbose=False, P=P)\n",
    "            \n",
    "            rd_LP = 0\n",
    "            for i, r in enumerate(rankings):\n",
    "                rd_LP += a[i] * fairness_measure(r, trueP, dist, m, n, g, k=rND_k)\n",
    "            \n",
    "            # print('Subset selection:')\n",
    "            rd_SS = fairness_measure(x_SS, trueP, dist, m, n, g, k=rND_k, verbose=False, P=P)\n",
    "            rd_det_greedy = fairness_measure(x_det_greedy, trueP, dist, m, n, g, k=rND_k)\n",
    "            \n",
    "            rd_uncons = fairness_measure(x_uncons, trueP, dist, m, n, g, k=rND_k)\n",
    "                \n",
    "            # Print and store resuults \n",
    "            if verbose: print('$'*15, rd_our, rd_LP, rd_greedy)\n",
    "            results_per_const[0].append(rd_our)\n",
    "            results_per_const[1].append(rd_LP)\n",
    "            results_per_const[2].append(rd_greedy)\n",
    "            results_per_const[3].append(rd_SS)\n",
    "            results_per_const[4].append(rd_det_greedy)\n",
    "            results_per_const[5].append(rd_uncons)\n",
    "            \n",
    "            utility_per_const[0].append(get_utility(W, x_our))\n",
    "            # utility_per_const[1].append(get_utility(W, x_LP))\n",
    "            u_LP = 0\n",
    "            for i, r in enumerate(rankings):\n",
    "                u_LP += a[i] * get_utility(W, r)\n",
    "            utility_per_const[1].append(u_LP)\n",
    "            utility_per_const[2].append(get_utility(W, x_greedy))\n",
    "            utility_per_const[3].append(get_utility(W, x_SS))\n",
    "            utility_per_const[4].append(get_utility(W, x_det_greedy))\n",
    "            utility_per_const[5].append(get_utility(W, x_uncons))\n",
    "        \n",
    "        results_mean[ijk] = np.array([np.mean(results_per_const[i]) for i in range(num_of_alg)])\n",
    "        results_std[ijk]  = np.array([np.std(results_per_const[i]) for i in range(num_of_alg)])\n",
    "        \n",
    "        utility_mean[ijk] = np.array([np.mean(utility_per_const[i]) for i in range(num_of_alg)])\n",
    "        utility_std[ijk] = np.array([np.std(utility_per_const[i]) for i in range(num_of_alg)])\n",
    "  \n",
    "    plot_res(results_mean, results_std, utility_mean, utility_std, ITER = ITERS,\\\n",
    "             fairness_measure = fairness_measure, name_occ_list = 'NA', name_occ_list2 = 'NA',\\\n",
    "             exp = 'UPDATED -- Image data (DCG Utility)', m = m, n = n, g = g, save = True, ylims=(0.45,0.9))\n",
    "        \n",
    "    return results_mean, results_std, utility_mean, utility_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.E Running simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_typical08, men_typical08, neutral08 = filter_occupations(0.8,0,0)\n",
    "\n",
    "neutral08.sort()\n",
    "men_typical08.sort()\n",
    "women_typical08.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "run_syn_exp_image(ITERS=1000, num_of_const_steps=10, rND_k=5, dist=np.ones(2)/2,\\\n",
    "                fairness_measure = compute_weighted_risk_diff, m =  500, n = 25, g = 2,\\\n",
    "                occ_list = men_typical08, occ_list2 = women_typical08,\\\n",
    "                name_occ_list = 'men_typical08', name_occ_list2 = 'women_typical08',\\\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "run_syn_exp_image(ITERS=1000, num_of_const_steps=10, rND_k=5, dist=np.ones(2)/2,\\\n",
    "                fairness_measure = compute_weighted_selec_lift, m =  500, n = 25, g = 2,\\\n",
    "                occ_list = men_typical08, occ_list2 = women_typical08,\\\n",
    "                name_occ_list = 'men_typical08', name_occ_list2 = 'women_typical08',\\\n",
    "                verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
